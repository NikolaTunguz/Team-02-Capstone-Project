{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concealed Pistol Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "\n",
    "#imports for vision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "#imports for preparing dataset\n",
    "import os\n",
    "import zipfile\n",
    "#from google.colab import files\n",
    "#from google.colab import drive\n",
    "\n",
    "#imports for visualizations\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 286\n",
      "Valid size: 35\n",
      "Test size: 37\n"
     ]
    }
   ],
   "source": [
    "#applying a transformation to the entire dataset, standardizing it\n",
    "#reshapes the image to guarantee a 256 size\n",
    "#grayscales the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#relative directory path\n",
    "#ImageFolder sets classes based on folder names\n",
    "dataset_dir = \"Data/ConcealedPistolDataset/\"\n",
    "dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)\n",
    "\n",
    "\n",
    "#initialize train, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))              #80% for training\n",
    "val_size = int(0.1 * len(dataset))                #10% for validation\n",
    "test_size = len(dataset) - train_size - val_size  #10% (remainder) for test\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "#print sizes of datasets\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Valid size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "#set the dataloaders to use the datasets\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#variable to define number of classes\n",
    "num_classes = 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
