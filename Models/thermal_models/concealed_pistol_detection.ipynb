{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concealed Pistol Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for neural network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "\n",
    "#imports for vision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "#imports for preparing dataset\n",
    "import os\n",
    "import zipfile\n",
    "#from google.colab import files\n",
    "#from google.colab import drive\n",
    "\n",
    "#imports for visualizations\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from custom_gun_dataset import CustomDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying a transformation to the entire dataset, standardizing it\n",
    "#reshapes the image to guarantee a 384 size\n",
    "#grayscales the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)), \n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "#relative directory path\n",
    "dataset_dir = '../Data/CombinedData'\n",
    "dataset = CustomDataset(root_directory = dataset_dir, transform = transform, categories = ['with gun', 'without gun'])\n",
    "\n",
    "#initialize train, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))              #80% for training\n",
    "val_size = int(0.1 * len(dataset))                #10% for validation\n",
    "test_size = len(dataset) - train_size - val_size  #10% (remainder) for test\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "#print sizes of datasets\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Valid size: {len(val_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "\n",
    "#set the dataloaders to use the datasets\n",
    "batch_size = 4\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#variable to define number of classes\n",
    "num_classes = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting device to GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting device to gpu if availible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#confirm device\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a grid of a single batch\n",
    "def show_batch(dataLoader):\n",
    "    for images, labels, boxes in dataLoader:\n",
    "        fig, ax = plt.subplots(figsize = (15, 10))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow = 8).permute(1, 2, 0))\n",
    "        break\n",
    "\n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition for a CNN\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        #model takes input of 384 x 384 x 1\n",
    "        #make sure in_channels aligns with out_channels from the previous layer\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn9 = nn.BatchNorm2d(128)\n",
    "\n",
    "        #16 x 16 x 128 comes from sizing, the pool in each layer cut dimensionality in half, 256 is out channels\n",
    "        self.fc1 = nn.Linear(in_features = (24 * 24 * 128), out_features = 64)\n",
    "        self.fc2 = nn.Linear(in_features = 64, out_features = 32)\n",
    "        #self.fc3 = nn.Linear(in_features = 32, out_features = 32)\n",
    "        #self.fc4 = nn.Linear(in_features = 32, out_features = 32)\n",
    "        self.fc_class = nn.Linear(in_features = 32, out_features = num_classes)\n",
    "        self.fc_bbox = nn.Linear(in_features = 32, out_features = 4)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        #forward pass first block, no pool\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        #output_pool_1 = self.pool(output)\n",
    "\n",
    "        #forward pass second block, pool\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        output_pool_2 = self.pool(output)\n",
    "\n",
    "        #forward pass third block, no pool\n",
    "        output = self.conv3(output_pool_2)\n",
    "        output = self.bn3(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        #output_pool_3 = self.pool(output)\n",
    "\n",
    "        #skip connection, connect 1-3\n",
    "        #skip1 = self.pool(input) #downsample\n",
    "        #if skip1.shape[1] != output.shape[1]:  # if channels differ, adjust\n",
    "        #    skip1 = nn.functional.pad(skip1, (0, 0, 0, 0, 0, output.shape[1] - skip1.shape[1]))\n",
    "        #output += skip1\n",
    "        output_skip_1 = output\n",
    "\n",
    "        #forward pass fourth block, pool\n",
    "        output = self.conv4(output_skip_1)\n",
    "        output = self.bn4(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        output_pool_4 = self.pool(output)\n",
    "\n",
    "        #forward pass fifth block, no pool\n",
    "        output = self.conv5(output_pool_4)\n",
    "        output = self.bn5(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        #output_pool_5 = self.pool(output)\n",
    "\n",
    "        #forward pass sixth block, pool\n",
    "        output = self.conv6(output)\n",
    "        output = self.bn6(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        output_pool_6 = self.pool(output)\n",
    "\n",
    "        #skip connection, connect 4-6\n",
    "        skip2 = self.pool(self.pool(output_skip_1)) #downsample\n",
    "        if skip2.shape[1] != output_pool_6.shape[1]:  # if channels differ, adjust\n",
    "            skip2 = nn.functional.pad(skip2, (0, 0, 0, 0, 0, output_pool_6.shape[1] - skip2.shape[1]))\n",
    "        output_pool_6 += skip2\n",
    "        output_skip_2 = output_pool_6\n",
    "\n",
    "        #forward pass seventh block, no pool\n",
    "        output = self.conv7(output_pool_6)\n",
    "        output = self.bn7(output)\n",
    "        output = self.leaky_relu(output)\n",
    "\n",
    "        #forward pass eigth block, pool\n",
    "        output = self.conv8(output)\n",
    "        output = self.bn8(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        output_pool_8 = self.pool(output)\n",
    "\n",
    "        #forward pass ninth block, no pool\n",
    "        output = self.conv9(output_pool_8)\n",
    "        output = self.bn9(output)\n",
    "        output = self.leaky_relu(output)\n",
    "\n",
    "        #skip connection, connect 6-9\n",
    "        skip3 = self.pool(output_skip_2) # downsample input to match spatial dims\n",
    "        if skip3.shape[1] != output.shape[1]:  # if channels differ, adjust\n",
    "            skip3 = nn.functional.pad(skip3, (0,0,0,0, 0, output.shape[1] - skip3.shape[1]))\n",
    "        output += skip3\n",
    "        output_skip_3 = output\n",
    "\n",
    "        #forward pass flattening\n",
    "        output = output.view(-1, 128 * 24 * 24)\n",
    "\n",
    "        #forward pass fully connected layers\n",
    "        output = self.fc1(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        output = self.fc2(output)\n",
    "        output = self.leaky_relu(output)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        #output = self.fc3(output)\n",
    "        #output = self.leaky_relu(output)\n",
    "        #output = self.dropout(output)\n",
    "\n",
    "        #output = self.fc4(output)\n",
    "        #output = self.leaky_relu(output)\n",
    "        #output = self.dropout(output)\n",
    "\n",
    "        output_class = self.fc_class(output)\n",
    "        \n",
    "        output_bbox = self.sigmoid(output)\n",
    "        output_bbox = self.fc_bbox(output_bbox)\n",
    "\n",
    "        return output_class, output_bbox\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "#channels, height, width\n",
    "summary(model,(1, 384, 384))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#adam optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of epochs and early stopping\n",
    "epochs = 500\n",
    "early_stopping_patience = 150\n",
    "early_stopping_counter = 0\n",
    "\n",
    "#using validation loss as the best model\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "#arrays to save each metric during training\n",
    "train_loss_values = []\n",
    "train_acc_values = []\n",
    "\n",
    "val_loss_values = []\n",
    "val_acc_values = []\n",
    "\n",
    "#training loop\n",
    "for epoch in range(epochs):\n",
    "    #turn on training mode\n",
    "    model.train()\n",
    "\n",
    "    #storing loss and accuracy per batch\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "\n",
    "    for data, label, boxes in train_dl:\n",
    "        #moving data to the right device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        #clear gradients, forward pass, loss, backward and update\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(data)\n",
    "        loss = criterion (output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #storing loss and accuracy over the batch\n",
    "        accuracy = (output.argmax(dim = 1) == label).float().mean().item()\n",
    "        train_losses.append(loss.item())\n",
    "        train_acc.append(accuracy)\n",
    "    \n",
    "    #average loss and acc over the epoch\n",
    "    current_epoch_loss = sum(train_losses) / len(train_losses)\n",
    "    current_epoch_acc = sum(train_acc) / len(train_acc)\n",
    "\n",
    "    #storing current epoch into overall loss and acc\n",
    "    train_loss_values.append(current_epoch_loss)\n",
    "    train_acc_values.append(current_epoch_acc)\n",
    "\n",
    "    #validation testing\n",
    "    #turn on evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    #storing loss and accuracy \n",
    "    val_losses = []\n",
    "    val_acc = []\n",
    "    \n",
    "    #disabling gradient tracking\n",
    "    with torch.no_grad():\n",
    "        for data, label, boxes in val_dl:\n",
    "            #moving data to the right device\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            #running forward pass and calculating loss\n",
    "            val_output, _ = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            #storing loss and accuracy\n",
    "            accuracy = (val_output.argmax(dim = 1) == label).float().mean().item()\n",
    "            val_losses.append(val_loss.item())\n",
    "            val_acc.append(accuracy)\n",
    "\n",
    "    #averaging loss and accuracy \n",
    "    current_epoch_val_loss = sum(val_losses) / len(val_losses)\n",
    "    current_epoch_val_acc = sum(val_acc) / len(val_acc)\n",
    "\n",
    "    #storing current epoch into overall\n",
    "    val_loss_values.append(current_epoch_val_loss)\n",
    "    val_acc_values.append(current_epoch_val_acc)\n",
    "\n",
    "    #checking for model improvement\n",
    "    if current_epoch_val_loss < best_val_loss:\n",
    "        #if best epoch, save it\n",
    "        torch.save(model.state_dict(), \"best_concealed_model.pth\")\n",
    "        \n",
    "        #best epoch information\n",
    "        best_val_loss = current_epoch_val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    #output current epoch information\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    print(f\"Training Accuracy: {current_epoch_acc:.3f}, Validation Accuracy: {current_epoch_val_acc:.3f}\")\n",
    "    print(f\"Training Loss: {current_epoch_loss:.3f}, Validation Loss: {current_epoch_val_loss:.3f}\")\n",
    "    print(f\"Current Best Epoch: {best_epoch}\\n\")\n",
    "\n",
    "    #stop if not improving\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(f\"Stopping early after {early_stopping_patience} epochs with no improvement\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Model Training Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch count\n",
    "epoch_count = []\n",
    "for i in range(len(train_loss_values)):\n",
    "    epoch_count.append(i + 1)\n",
    "\n",
    "#setting figure size\n",
    "plt.figure(figsize = (8, 4))\n",
    "\n",
    "#plotting loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(epoch_count, train_loss_values, label='Training Loss')\n",
    "plt.plot(epoch_count, val_loss_values, label='Validation Loss', linestyle='--')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "#plotting accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(epoch_count, train_acc_values, label='Training Acc')\n",
    "plt.plot(epoch_count, val_acc_values, label='Validation Acc', linestyle='--')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "#showing figures\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading best saved model\n",
    "model.load_state_dict(torch.load('best_concealed_model.pth', weights_only=True))\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval() \n",
    "\n",
    "# Disabling gradient tracking\n",
    "with torch.no_grad(): \n",
    "    total_accuracy = 0.0\n",
    "    total_test_loss = 0.0\n",
    "    num_batches = len(test_dl)\n",
    "\n",
    "    for data, label, bbox in test_dl:\n",
    "        # Loading data and labels to proper device\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # Forward pass, loss, accuracy calculation\n",
    "        output, _ = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        # Get predictions (argmax over the output logits)\n",
    "        preds = output.argmax(dim=1)\n",
    "        \n",
    "        accuracy = (preds == label).float().mean()\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        total_accuracy += accuracy.item() \n",
    "        \n",
    "        # Show misclassified images\n",
    "        for idx in range(len(preds)):\n",
    "            img_tensor = data[idx].cpu()\n",
    "            img_np = img_tensor.squeeze().numpy()  # For grayscale\n",
    "\n",
    "            plt.imshow(img_np, cmap='gray')\n",
    "            plt.title(f\"Predicted: {preds[idx].item()}, Actual: {label[idx].item()}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    # Calculate the average loss and accuracy over all batches\n",
    "    avg_loss = total_test_loss / num_batches\n",
    "    avg_accuracy = total_accuracy / num_batches\n",
    "\n",
    "    print(f\"Test Accuracy: {avg_accuracy:.3f}\")\n",
    "    print(f\"Test Loss : {avg_loss:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
